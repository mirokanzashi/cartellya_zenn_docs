---
title: "生成モデル"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- 生成モデルはどのようなものを理解する

## キーワード
識別モデル, 生成モデル, 拡散モデル, フローベース生成モデル

## 学習内容

### 識別モデル(Discriminative Model)
- 与えられた入力がどのクラスに属するかを学習するモデル
- P(y|x)（入力xが与えられたときの、出力yの確率）を学習
- データの分布そのものは学ばず、「分類の境界」を学ぶ
- 例：画像認識、物体検出

### 生成モデル(Generative Model)
- データ自体を生成できるようにすることを目的とするモデル
- P(x,y) またはP(x)（データとラベルの同時分布、またはデータの分布そのもの）を学習
- データの構造やパターンを学び、新しいデータを「作り出す」ことができる
- 例：画像生成、テキスト生成、異常検知

### 拡散モデル(Diffusion Models)
- ノイズからデータを徐々に再構成する生成モデル
- 学習は時間ステップに分けて行われる
- 高品質な生成が可能
- 推論（生成）はやや遅い（多ステップ必要）

#### 流れ
- 順方向過程(forward process)：画像などのデータに少しずつガウスノイズを加えていき、最終的に完全なノイズにする（拡散）
- 逆方向過程(reverse process)：学習したモデルが、そのノイズから徐々にデータを復元する（生成）

### フローベース生成モデル(Flow-based Models)
- 可逆な変換（invertible mapping）を使って、ノイズとデータを相互に変換する生成モデル
- 明示的な確率分布P(x)を扱える
- 推論が高速（1ステップ）でできる
- 可逆性を保つため、ネットワーク設計に制約がある

#### 特徴
- ノイズ空間（潜在空間）とデータ空間を可逆な関数で結びつける
- 潜在変数（通常はガウス分布）をデータに変換するだけで画像などを生成できる

### 拡散モデルとフローベースモデルの比較
| 比較項目    | 拡散モデル                          | フローベース生成モデル         |
| ------- | ------------------------------ | ------------------- |
| 生成方式    | ノイズ→徐々に復元（多ステップ）               | 潜在変数→可逆関数（1ステップ）    |
| 学習の難易度  | 比較的安定                          | 変換関数が制限されるため設計が難しい  |
| 推論速度    | 遅い（多ステップ）                      | 速い（1ステップ）           |
| 表現力・品質  | 非常に高い（特に画像）                    | やや制限される（ただし高速）      |
| 確率密度の計算 | できない（明示的でない）                   | できる（明示的な P(x) を持つ）  |
| 有名モデル例  | Stable Diffusion, Imagen, DDPM | Glow, RealNVP, NICE |
