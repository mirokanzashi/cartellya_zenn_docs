---
title: "誤差計算"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- 出力層で使用する活性化関数を勉強します

#### モデル訓練のステップ
1. アーキテクチャの設計
2. 入力層設計
3. 中間層設計
4. 出力層設計
5. **誤差計算**
6. モデルに誤差を反映する
7. 重みの更新の設定をする
8. 最適なモデルを手に入れる

## キーワード
損失関数, 出力ユニット, クロスエントロピー誤差

## 学習内容

### 損失関数(loss function)
- 正解と出力との差を定量化したものをいいます
- コスト関数、損失関数、誤差関数、コスト、損失、誤差などと表現されます
- コストが小さいものほどいいモデルとなりまして、誤差が最小になっている状態を「最適」といいます
- 損失関数がモデルの「学習の方向」を決めます。正しく選ばないと、モデルが間違った方向に学習してしまいます



### 出力ユニット別：回帰
- 平均絶対誤差(MAE)

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} \left| y_i - \hat{y}_i \right|
$$

- 平均二乗誤差(MSE)

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} \left( y_i - \hat{y}_i \right)^2

$$


https://zenn.dev/cartellya/articles/cartellya_20250511005035_e-memo-00013

### 出力ユニット別：2値分類
- 2値分類は二つのクラスを分類することが目的です

#### バイナリクロスエントロピー

$$
\mathcal{L}(y, \hat{y})= - \sum_{i=1}^{n} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
$$

### one-hotベクトル
- 一つの要素が1で、他の全ての要素が0となるベクトルです
- 使用する理由は、カテゴリ変数を数値として表現する時、順序が意味を持たない場合があります。one-hotベクトルを使うと、順序に偏りのないデータを作成できます
- 特徴として、ベクトル長はクラス数と同じです

**例：3クラス分類(クラス数=3)**
| クラス | one-hot表現  |
| --- | ---------- |
| 0番  | [1, 0, 0] |
| 1番  | [0, 1, 0] |
| 2番  | [0, 0, 1] |



### 出力ユニット別：多クラス分類
#### クロスエントロピー誤差(Cross Entropy Loss)
- 特徴
    - 確率的な予測に適している：出力が「どれくらい正しい確率を出しているか」を評価
    - 誤差が大きくなりやすい：間違っているときは大きく罰せられる（学習が進みやすい）
    - ソフトマックス関数との相性が良い

$$
\mathcal{L}(t, y) =- \sum_{k=1}^{K} t_k \log(y_k)
$$

$t_k$：正解（one-hotベクトル）
$y_k$：予測値