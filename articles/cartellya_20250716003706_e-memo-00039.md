---
title: "Transformer"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- Transformerを勉強する

## キーワード
transformer, source-target attention, self-attention,
positional encoding, multi-head attention, masked self attention,
scaled dot-product attention

## 学習内容
### transformerとは
- RNNを使わずに系列データを処理できるアーキテクチャである
- attentionを中心に設計された
- すべての位置の単語に同時に注意を向けられるモデル
- 並列計算でき、長距離依存関係も扱える

| 従来（RNNなど）     | transformer（改善点）           |
| ------------- | -------------------------- |
| 時系列処理が逐次的 | 全位置を同時に処理（並列）          |
| 長文での依存関係に弱い   | self-attentionで全体を参照可能 |
| 計算が遅く、勾配消失が発生 | attentionで安定、計算効率が良い       |

### source-target attention
- RNNが持っているエンコーダとデコーダの間で橋渡しの役割を持つattention機構のこと
- encoder-decoder attention、cross-attentionとも呼ばれる
- keyとvalueはエンコーダの隠れ層からきて、queryはデコーダの隠れ層からくる

### self-attention
- transformerの中核
- source-target attentionでは、入力文と出力文の単語間の関連度を計算したが、self-attentionは入力文内の単語間または、出力文内の単語間の関連度を計算した
- self-attintion は文内の単語間の関係を直接計算できるが、語順の情報が失われた。これを回避するために、**位置エンコーディング(positional encoding)**と呼ばれる単語の出現位置に固有の情報を入力に付加する
- queryとkeyとvalueは全て同じ場所からくる。これがselfといわれている理由

#### エンコーダとデコーダ
- どちらもself-attentionを用いている
- デコーダはsource-target attentionにより入力文の情報も利用するが、エンコーダはself-attentionのみ使う
- エンコーダは入力文の全ての単語を見ながら計算を行うが、デコーダでは先頭から順に出力を生成するため、まだ出力していない未来の情報は使えない
    - デコーダで使う場合は、未来の入力を考慮することがないように，マスク付きに改良している→ 予測対象の単語の情報が事前に漏れるのを防ぐ目的(masked self attention)

### query, key, valueによるattentionの計算

#### query, key, value
- 画像の一番左のところでquery, key, valueを入力値として使われることを表示した

#### エンコーダ
- Inputsとpink背景色のInput Embedding処理はエンコーダ層
- positional encodingで位置情報を持っている

#### デコーダ(self-attention)
- pink背景のOutput Embeddingは過去の出力を入力として使われる
- multi-head attentionはmaskされた(masked multi-head attention)
- positional encodingで位置情報を持っている

#### デコーダ(source-target attention)
- エンコーダの出力情報を入力情報のkeyとvalueとして使われる
- queryはデコーダの中間情報(masked multi-head attentionの出力情報)を利用する
- output probabilitiesはここで処理した最終出力情報


![](/images/e-memo-00039_01.webp)
*出典：
Abdullah Afify, A detailed simplified explanation of the Transformers architecture.(2023),https://medium.com/@abdullah.afify/a-detailed-simplified-explanation-of-the-transformers-architecture-125c3b33b6cb*

### multi-head attention
- 1回のattentionだけでは捉えられない複雑な関係を、複数の異なる注意の視点から並列に学習するしくみ
- 各attentionの計算をheadと呼ばれる（画像の真ん中のmulti-head self attention layerのh）
- headの数だけ異なる全結合層を用意する
- こうすると各headがそれぞれ視点の異なるパターンでqueryとkeyとの関係を見ることができる


#### scaled dot-product attention
- 画像の一番左がscaled dot-product attention
- queryとkeyの関連度を計算し、valueから重要な情報を抽出する


### 画像内容の左と真ん中を整理する
> 左のScaled Dot-Product Attentionをattentionと呼ぶ
> 真ん中のmulti-head self attention layerをlayerと呼ぶ

- layerで生成された各ヘッド専用のquery, key, value（線形変換後のベクトル）は、左側の attentionの入力になる
- attentionの出力（各ヘッドごとに1個）をまとめたものが「複数のhead（= Multi-Head）」である

| 部分                   | 内容                   | 対応                  |
| --------------------- | ------------------- | -------------------- |
| layerの linear 層   | Q, K, Vに異なる重みをかけて各ヘッド用に変換 | 入力 → 各 head用    |
| scaled dot-product attention | 各ヘッドごとの実際の注意計算   | 入力：Qₕ, Kₕ, Vₕ   |
| 出力の concat          | 各ヘッドの出力を連結       | $head1, head2, ..., head8$ |
| 最終 linear      | 結合出力を元の次元数に戻す    | transformerブロックへ出力         |

