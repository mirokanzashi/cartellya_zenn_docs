---
title: "距離計算"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","機械学習"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::

## 概要
- シラバス：E資格2024#2
- 距離計算の数式を知ります

## キーワード
コサイン距離, コサイン類似度, ユークリッド距離, マンハッタン距離,
マハラノビス距離, Lp距離

## 学習内容

#### コサイン距離とコサイン類似度
- コサイン類似度：2つのベクトルがどれだけ似ているかを測定するために使用される指標
- 公式：

> $\vec{A}=(a_1,a_2); \vec{B}=(b_1,b_2)$

$$
Cosine Similarity(\vec{A},\vec{B}) = \frac{\vec{A} \cdot \vec{B}}{\|\vec{A}\| \cdot \|\vec{B}\|}=\frac{a_1a_2+b_1b_2}{\sqrt{a_1^2+b_1^2}\cdot \sqrt{a_2^2+b_2^2}}
$$

$\vec{A} \cdot \vec{B}$：AとBの内積
$\|\vec{A}\| , \|\vec{B}\|$：AとBのノルム（ベクトルの大きさ）


- 特徴
    - 0に近いほど似ている（類似度が高い）
    - 1に近いほど異なる（類似度が低い）
    - ベクトルのスケール（大きさ）には影響されず、向きの違いだけで距離を測定
    - 値の範囲は-1~1


![](/images/e-memo-00008_01.gif)
*出典：@IT, コサイン類似度のイメージ, コサイン類似度（Cosine Similarity）とは？(2024), https://atmarkit.itmedia.co.jp/ait/articles/2112/08/news020.html*

----
- コサイン距離：2つのベクトル間の角度のコサインを用いて計算される距離指標です
- 公式：1-Cosine Similarity
- 特徴：
    - 値の範囲は0~2

----
**コサイン類似度とコサイン距離 の比較**

| 項目      | コサイン類似度      | コサイン距離     |
| ------- | --------------------------------------------- | ------------------------------ |
| 数式   | $\cos(A,B) = \frac{A \cdot B}{\|A\|\|B\|}$ | $1 - \text{Cosine Similarity}$ |
| 値の範囲 | -1〜1                            | 0〜2             |
| 意味   | 値が**大きいほど似ている**               | 値が**小さいほど似ている**        |
| 用途   | 「どれくらい似てるか」知りたいとき             | 距離として使いたいとき（例えばクラスタリング、最近傍探索）         |


### ユークリッド距離
- 両点の間の「直線距離」
- ピタゴラスの定理の公式で計算します
- L2ノルムとも呼ばれます
- 公式：$d^2=a^2+b^2$

### マンハッタン距離
- 点xから点yまでの距離を求める際に、座標の差（の絶対値）の総和を2点間の距離とする指標です
- L1ノルム、タクシー距離（Taxicab Distance）とも呼ばれます
- 公式：$d(x,y) = \sum_{i=1}^{n} |x_i - y_i|$


**ユークリッド距離とマンハッタン距離の比較**
| 距離の種類    | 計算方法           | 特徴             |
| -------- | -------------- | -------------- |
| ユークリッド距離 | 直線距離（ピタゴラスの定理） | 最短距離、L2ノルム     |
| マンハッタン距離 | 縦+横の距離（絶対値の和）  | L1ノルム、直角移動の総距離 |

![](/images/e-memo-00008_02.gif)
*出典：@IT, マンハッタン距離／ユークリッド距離のイメージ, マンハッタン距離（Taxicab distance）／ユークリッド距離（Euclidean distance）、L1／L2ノルムとは？(2024), https://atmarkit.itmedia.co.jp/ait/articles/2111/10/news023.html*

### マハラノビス距離
- データの外れ具合を定量化する指標です
    - 仮にユークリッド距離が同じでも、点の位置が異なるので、分布からの外れ具合（分散）も違いますので、マハラノビス距離が異なります

**この画像を参考してください**
![](/images/e-memo-00008_03.jpg)
*出典：yutera12(tera), マハラノビス距離を徹底解説(2022), https://qiita.com/yutera12/items/db425fafce2d87a25a1f*



- 公式：$D_M(\vec{x}, \vec{\mu}) = \sqrt{(\vec{x} - \vec{\mu})^T \, \Sigma^{-1} \, (\vec{x} - \vec{\mu})}$
    - $\vec{x}$：対象のデータ点（ベクトル）
    - $\vec{\mu}$：平均ベクトル（分布の中心）
    - $\Sigma^{-1}$：共分散行列の逆行列
    - T：行列の転置

:::message
**分散共分散行列とは**

$$
\Sigma =
\begin{bmatrix}
\mathrm{Var}(X_1) & \mathrm{Cov}(X_1, X_2) & \cdots & \mathrm{Cov}(X_1, X_n) \\
\mathrm{Cov}(X_2, X_1) & \mathrm{Var}(X_2) & \cdots & \mathrm{Cov}(X_2, X_n) \\
\vdots & \vdots & \ddots & \vdots \\
\mathrm{Cov}(X_n, X_1) & \mathrm{Cov}(X_n, X_2) & \cdots & \mathrm{Var}(X_n)
\end{bmatrix}

$$
- 対角成分：各変数の分散（バラつき）
- 非対角成分：共分散（変数間の関係）
- 分散$\mathrm{Var}(X)$：「各データが平均値からどれだけ離れているか」という、データのバラつき具合です
- 共分散$\mathrm{Cov}(X)$：複数データ群を考慮した分散です
----
例えば、生徒の数学の点数と英語の点数データがあります
- 分散とは、生徒の点数（数学、もしくは英語）が平均点数からどれだけ離れています
- 共分散とは、生徒の数学点数と英語点数はどのような関係を知りたいです
- 数学が得意な生徒は英語も得意で、数学が苦手な生徒はやっぱり英語もダメ、という場合には正の値になります。
- 数学が得意だと英語が苦手という傾向がある場合には負の値になります
:::


### Lp距離
- 一般化された距離（ノルム）を表します
- 2点間の差の絶対値をp乗した和を1/p乗した距離
- p=1：マンハッタン距離(L1ノルム)
- p=2：ユークリッド距離(L2ノルム)


$$
d(\vec{x}, \vec{y}) = \left( \sum_{i=1}^{n} |x_i - y_i|^p \right)^{\frac{1}{p}}
$$