---
title: "並列分散処理"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- モデル並列分散処理の方法を勉強する

## キーワード
分散深層学習, データ並列, モデル並列, ハイブリッド並列, パラメータ同期方式

## 学習内容

### 分散深層学習(Distributed Deep Learning)
- 深層学習モデルの学習処理を複数の計算ノードやデバイス（GPU・CPU・クラスタ）に分散させて並列実行する手法の総称
- 目的は学習時間の短縮とより大規模なモデル・データセットへの対応
- 並列化アプローチ
    - データ並列
    - モデル並列
    - ハイブリッド並列

### データ並列(Data Parallelism)
- 同じモデルを複数のデバイスに複製
- 各デバイスに異なるデータのミニバッチを割り当て、勾配を計算後に同期
- 特徴：実装が簡単、ほとんどのケースで有効

### モデル並列(Model Parallelism)
- モデルを複数のデバイスに分割
- 巨大モデル（GPT-4など）をパラメータ単位で複数GPUに配置
- 特徴：モデルが大きすぎて単一GPUに載らないときに必須
- 異なるネットワークのマシンでこの処理を行う場合、データ通信が大きなボトルネックになることもある

### ハイブリッド並列(Hybrid Parallelism)
- データ並列とモデル並列を組み合わせる
- 大規模言語モデル（LLM）や超大規模Vision Transformerなどで採用

### パラメータ同期方式
- 同期型：すべてのワーカーが勾配を計算し終わるまで待つ
- 非同期型：ワーカーが独立して更新し、遅れて同期	