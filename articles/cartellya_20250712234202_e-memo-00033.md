---
title: "畳み込みニューラルネットワークの構造"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- 畳み込みニューラルネットワークの構造を勉強する

## キーワード
ストライド, パディング, ゼロパディング, im2col,
プーリング, Max pooling, Mean pooling, LP Pooling,
全結合層, Global Average Pooling

## 学習内容

### CNNの構造
- 入力層(Input Layer)：画像データ
- 畳み込み層(Convolutional Layer)： フィルタ（カーネル）で画像をスキャンして、特徴マップ（特徴量）を抽出。例: エッジ、線、角など
- プーリング層(Pooling Layer)：特徴マップを縮小して、計算量を減らし、位置のずれに強くする
- 全結合層(Fully Connected Layer)：最終的に分類などのために使われる。通常のニューラルネットワークと同じ構造
- 出力層(Output Layer)：ソフトマックス関数などで、クラスごとの確率に変換し、予測を出力

![](/images/e-memo-00033_01.jpg)
*出典：
DeepAge, 定番のConvolutional Neural Networkをゼロから理解する(2016), https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html#%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%81%A8%E3%81%AF*


### ストライド
- カーネルを入力上で何ピクセルずつ動かしていくかを示す重要なハイパーパラメータである
    - ストライド1：カーネルは1ピクセルずつずれて移動します（細かく見る）
    - ストライド2以上：2ピクセルずつ移動します（大まかな特徴を捉える）

![](/images/e-memo-00033_02.png)

![](/images/e-memo-00033_03.png)

### パディング
- フィルター処理を行うと、フィルターサイズによって入力画像と出力画像のサイズが変わってしまう
- 畳み込み演算前に入力データの周囲に固定のデータを埋めておくパディング処理をしておくことで、入力画像と同じサイズの特徴マップを得られる
- パディングにより、端のデータに対しての畳み込みが増え、端の特徴も考慮されるようになる
- ゼロパディング：0を埋めるパディング

![](/images/e-memo-00033_04.png)


### 出力サイズの計算

$$
O_w=\frac{W+2P-F_w}{S}+1
$$
$$
O_h=\frac{W+2P-F_h}{S}+1
$$

W,H：画像の幅と高さ
$O_w,O_h$：出力の幅と高さ
$F_w,F_h$：フィルタの幅と高さ
P：パディング
S：ストライド

###  im2col（image to column）
- 畳み込み演算を効率的に行うために、入力画像を行列に変形する手法
- 畳み込みを「行列×行列の掛け算」に変換でき、CPUやGPUで高速化しやすくなる
- デメリットはメモリ使用量が増える

### プーリング
- 畳み込み層の後に適用される。入力データをより扱いやすい形に変形するために、情報を圧縮し、down samplingする。
- このように情報を圧縮することで
    - 微小な位置変化に対してロバストになる
    - ある程度過学習を抑制する
    - 計算コストを下げる

#### Max poolingとMean pooling(Average Pooling)
- Max pooling：フィルター内の数値の最大値を取る
- Mean pooling：フィルター内の数値の平均値を取る


![](/images/e-memo-00033_05.png)

#### LP Pooling
- CNNにおける一般化されたプーリング手法で、max poolingやmean poolingを含む、より柔軟なプーリング方法
- 平均寄り/最大値寄りに制御できる

### 全結合層(Fully Connected)
- の畳み込み層やプーリング層が出力した特徴マップをベクトルに変換（flatten）し、すべてのノードが次の層のすべてのノードとつながる
- すべてのノードとつながるので、パラメータ数が多く、過学習しやすい、大量メモリを消費する

### Global Average Pooling
- 全結合層のデメリットを回避するため、開発した手法
- CNNの最終段において、特徴マップの空間方向の平均をとって、各チャネルごとに1つの値に要約する操作

#### 比較
| 項目  | Global Average Pooling | 全結合層 |
| ----- | ---------------------- | --------------------- |
| 入力    | 画像サイズそのまま（H×W×C）       | flatten（1次元化）         |
| 出力    | チャネル数（C次元）             | 任意のサイズ（例：128 → 10）    |
| パラメータ | なし（学習なし）               | あり（大量の重みとバイアス）        |
| 過学習耐性 | 高い                     | 低い（正則化が必要）            |
| 解釈性   | 比較的高い                  | 低い                    |
