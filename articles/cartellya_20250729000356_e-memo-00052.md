---
title: "SSD"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- SSDを勉強する

## キーワード
SSD, デフォルトボックス, Non-Maximum Suppression, IoU,
ハードネガティブマイニング, ネガティブサンプル


## 学習内容

### SSD（Single Shot MultiBox Detector）
- 1回の畳み込み処理（Single Shot）で、複数の物体の位置とクラスを同時に検出するモデル
- YOLOよりも精度が高く、小さな物体にも強い

### デフォルトボックス（Default Box）
- SSDでは、画像中の複数の場所に、あらかじめサイズ・アスペクト比の異なる「候補ボックス」を配置
- 各ボックスについて、「どの物体に対応しているか」を予測する（= バウンディングボックスの補正）
- これにより、1つの画像に複数サイズ・複数種類の物体がある場合にも柔軟に対応できる

#### デフォルトボックスとFaster R-CNNのアンカーボックスの比較
**共通点**
| 内容      | 説明                                                                 |
| ------- | ------------------------------------------------------------------ |
| 学習対象 | どちらも「事前定義された矩形」に対して、「実際の物体とのオフセット（中心・サイズの補正）」を学習します                |
| 目的 | ネットワークに「矩形候補を1から学習させる」のではなく、「すでに定義された候補を調整させる」ことによって、学習を安定化・高速化します |

| 観点        | SSD（Default Box）        | Faster R-CNN（Anchor）     |
| --------- | ----------------------- | ------------------------ |
| アプローチ     | 一括予測（Single Shot）       | 段階的（RPNで提案 → クラス分類）      |
| 処理速度      | 高速（リアルタイム可）             | 遅め（高精度だがリアルタイムは厳しい）      |
| 精度傾向      | 高速・中精度、小さな物体にやや弱い（改善可能） | 高精度、小さな物体にも対応可能（FPN併用など） |
| 特徴マップの使い方 | 複数の解像度を同時に使う            | 通常は1つ（FPNなどで補うことは可能）     |
| 配置の方法 | 複数の特徴マップ（スケール）上に均等に配置 | 特徴マップ上の各位置に固定サイズ＆比率で配置 |
| 使い方 | 各デフォルトボックスごとに、分類＋位置補正 | 各アンカーに対して、分類＋位置補正を学習 |
| 小さい物体への対応 | 小さい特徴マップでは小さなデフォルトボックスを使う | 特徴ピラミッドを併用するか、FPNなどで対応 |

### 仕組み
1. ベースCNNで特徴抽出
2. 特徴マップの複数のスケール（サイズ）から物体を検出
3. 各スケールごとに複数の「デフォルトボックス」を事前に配置
4. 各ボックスに対して：クラス分類、バウンディングボックスのオフセット回帰
5. 最後にNon-Maximum Suppression(NMS)で重複を除去


### Non-Maximum Suppression（NMS）
- 物体検出で「重複している検出ボックス」を除去して、最も信頼度が高いものだけを残す処理
- 物体検出モデルの出力の**最後の後処理**
- パラメータ：
    - IoUしきい値：どの程度重なっていたら削除するか
    - 信頼度しきい値：低すぎる予測は除く

#### 処理の流れ
1. 予測ボックスを信頼度スコア順にソート→ 信頼度（confidence）が高い順に並べる
2. 最もスコアの高いボックスを残す（1個選ぶ）
3. 重なり具合はIoUで判定して、残したボックスと重なりの大きい他のボックスを削除
    - IoUがしきい値（例：0.5）より大きければ「重複している」と見なして削除
4. 残ったボックスで繰り返す

#### IoU（Intersection over Union）
- 2つのボックスの「重なり率」
- 値が0〜1の範囲（1なら完全一致）

$$
IoU=\frac{重なった面積}{２つのボックス和の面積- 重なった面積}
$$

### ハードネガティブマイニング（Hard Negative Mining）
- 物体検出（例：SSD, Faster R-CNN）や2値分類問題で、「学習を効率化し、精度を高めるための工夫」である
- 学習に使うネガティブサンプルのうち、難しいものだけ選んで学習する
- ネガティブサンプルの中から、損失（誤差）が大きいものを探して、上位から一定数だけ選んで学習に使う（例：ポジティブ：ネガティブ = 1:3）
- メリット：学習効率向上、精度向上、過学習防止
- 適用モデルの例：SSD、Faster R-CNNなど

#### ネガティブサンプル
- ポジティブサンプル：検出すべき「物体そのもの」
- ネガティブサンプル：背景や不要な領域（物体じゃない）
- 物体検出では、画像中の大部分が背景（ネガティブ）で、ポジティブよりはるかに多い

#### ハードネガティブ
- 間違いやすい背景= Hard Negative
- ネガティブ（背景）を全て学習に使うと、数が多すぎて学習が背景に偏る
- 簡単な背景ばかり学習しても意味がない
- なので、間違いやすい背景だけ選んで学習したほうがいい
