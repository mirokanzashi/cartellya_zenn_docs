---
title: "ハイパーパラメータの最適化"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- ハイパーパラメータの定義と最適化の手法を勉強する


#### モデル訓練のステップ
1. アーキテクチャの設計
2. 入力層設計
3. 中間層設計
4. 出力層設計
5. 誤差計算
6. モデルに誤差を反映する
7. 重みの更新の設定をする
8. **最適なモデルを手に入れる**

## キーワード
ハイパーパラメータ, グリッドサーチ, ランダムサーチ, ベイズ最適化

## 学習内容

### ハイパーパラメータ
- モデル自身が学習するのではなく、人間（または外部プログラム）があらかじめ決める値
- 最適化のハイパーパラメータの値を調整していくことをハイパーパラメータチューニングと呼ぶ

#### ハイパーパラメータとパラメータの違い
| 項目     | パラメータ            | ハイパーパラメータ          |
| ------ | ---------------- | ------------------ |
| 誰が決めるか | モデルが学習して決める  | 人間が事前に設定する     |
| 例      | ニューラルネットの重みやバイアス | 学習率、エポック数、バッチサイズなど |
| 役割     | モデルの「振る舞い」を定める   | 学習の「方法や条件」を定める     |

### グリッドサーチ
- ある一定の範囲内でハイパーパラメータを複数個設定し、モデルを構築、すべての候補の組み合わせを総当たりで試す方法

#### 特徴
- 並列化しやすい
- 実装も理解も簡単で、直感的に使いやすい
- 候補をすべて試すので、見落としがない
- 計算量がパラメータ数によって、指数関数的に増加するため計算コストが高い

### ランダムサーチ
- あらかじめ決めた範囲内からランダムに選んだパラメータセットで評価を行う方法
- 探索範囲（例えば 学習率 = 0.0001 ～ 1.0）を決めておけば、連続値のパラメータにも対応できる

#### 特徴
- 効率が良い
- 連続的な探索が可能
- 見落としの可能性
- 局所・大域的最適解を見つける力が貧弱
- 再現性が低い


### ベイズ最適化
- 計算コストの高い関数（＝ハイパーパラメータの性能評価など）を、効率的に最適化するための手法
- 特に、ハイパーパラメータチューニングなど「何回も試すのが大変」な最適化問題に向いている

#### 特徴
| 特徴            | 内容                            |
| ------------- | ----------------------------- |
| 試行回数が少なくて済む | グリッドサーチやランダムサーチよりも効率が良い       |
| 賢く探す        | すでに試した点の結果をもとに「次にどこを試すか」を判断   |
| 黒箱関数に対応     | 関数の式や勾配が不明でも使える（＝ブラックボックス最適化） |
