---
title: "入力層設計"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- ニューラルネットワークの入力層を勉強します

#### モデル訓練のステップ
1. アーキテクチャの設計
2. **入力層設計**
3. 中間層設計
4. 出力層設計
5. 誤差計算
6. モデルに誤差を反映する
7. 重みの更新の設定をする
8. 最適なモデルを手に入れる

## キーワード
Min-Max正規化, バッチ学習, オンライン学習, ミニバッチ学習,
バッチサイズ, エポック, イテレーション

## 学習内容


### 正規化
#### 効果
- 学習の高速化
- 過学習の抑制
- 勾配消失の抑制

#### データの正規化（前処理時）
- 学習前に入力データに行う処理
- 目的：入力スケールの統一
- 例：Min-Max正規化

#### ネットワーク内部の正規化
- 学習中に各層の出力や中間表現を正規化します
- 目的：学習の安定化・効率化



#### Min-Max正規化(Min-Max normalizer)
- データ正規化の手法
- 値を0～1にスケーリング
- ある程度連続性があり、一様分布が想定されているデータに使用します
- 数式： $Y=\frac{X-x_{min}}{x_{max}-x_{min}}$
X: データ
Y：正規化した結果

身長(100cm～190cm)、体重（30kg～90kg）のように数字の単位によって数値に開きがある場合、数値が大きい方に重要度が偏ってしまうので、0～1の値に正規化して数値を均します。

#### バッチ学習(batch learning)
- ネットワーク内部の正規化の手法
- オフライン学習とも呼ばれます
- 全データをまとめて使ってモデルを一括で訓練する方法です

:::message
**バッチ(batch)**：学習時に一度に処理するデータのまとまりのことです
:::

#### オンライン学習(online learning)
- ネットワーク内部の正規化の手法
- データが来るたびに少しずつ学習する方式

#### ミニバッチ学習(mini-batch learning)
- ネットワーク内部の正規化の手法
- バッチ学習のバリエーション
- 全データを少しずつ使って、複数回に分けて学習する方法です

:::message
**バッチサイズ**：一度のパラメータ更新に使うデータの数を指します
:::

#### バッチに関する3つの学習の比較

| 比較項目   | オンライン学習           | バッチ学習 |
| ------ | ----------------- | -------------- |
| 学習方式   | データを1件ずつ処理しながら更新  | 全データを使ってまとめて学習 |
| データサイズ | 無限や非常に大きいデータでも対応可 | メモリに収まるデータが前提  |
| 学習速度   | データ1件ごとにすぐ反映される   | 1エポック毎に更新される   |
| 柔軟性    | 新しいデータにもすぐ対応      | モデルの再学習が必要     |
| ノイズ耐性  | 高いノイズに弱い傾向あり      | 平均化により安定しやすい   |

:::message
**エポック(epoch)**:データセット全体を1回学習に使うこと
1エポック=全データ÷バッチサイズ 回の重み更新
エポック数：エポックを何回繰り返すか
:::



| 学習スタイル                           | 特徴            | 使用データ数 | 長所・短所                |
| -------------------------------- | ------------- | ------ | -------------------- |
| バッチ学習        | 全データを一度に使って学習 | 全データ   | 精度が高いが重い             |
| オンライン学習     | 1件ずつ順番に学習     | 1データ   | 軽いが不安定               |
| ミニバッチ学習 | 少数のデータごとに学習   | 数十～数百件 | 安定性と効率のバランスが良い（よく使う） |


#### イテレーション数
- ミニバッチ1つでモデルを更新する1回の処理です
- イテレーション数 ＝ データ数 ÷ バッチサイズ × エポック数

| 用語          | 意味           |
| ----------- | ------------ |
| エポック    | 全データを1回学習に使う |
| バッチサイズ  | 1回の学習に使うデータ数 |
| イテレーション | 1バッチごとの重み更新  |


例：1000件のデータをモデルに3回を学習させます。毎回の学習はデータを200件ずつでモデルに渡せます。
バッチサイズ：200
イテレーション：5
エポック数：3

こちらの記事も参考になれると思います
https://zenn.dev/nekoallergy/articles/ml-basic-epoch