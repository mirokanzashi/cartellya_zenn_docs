---
title: "距離学習"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- 距離学習の手法を勉強する

## キーワード
表現学習, Siamese Network, Contrastive Loss, Triplet Network, Triplet Loss

## 学習内容
### 表現学習(Representation Learning)
- データから特徴（表現、ベクトル）を自動的に抽出・学習する手法のこと
- 従来は人手で特徴量設計（特徴抽出）を行っていた→ 専門知識が必要で、大規模データには対応困難
- 表現学習は、生のデータ（画像、音声、テキストなど）から、そのまま機械学習に使える有用な特徴を自動で学習する
#### 特徴
- 教師あり・教師なしどちらも可能
    - 教師なし学習が盛ん（例：自己教師あり学習）
- 特徴量設計の自動化で専門家の工数削減
- 汎用的な特徴が得られれば、多様なタスクに転用可能

#### 運用例
- 自己符号化器（Autoencoder）：入力を圧縮して潜在空間に写像し、再構成を目指す
- 深層ニューラルネットの中間層出力：CNNの中間層の特徴マップは画像の抽象的な特徴を表す
- Word2Vec、BERTなどの言語モデル：単語や文の意味的なベクトル表現を学習
- 距離学習


### 距離学習(Metric Learning)
- データ間の類似度（距離）をうまく測れるように学習する手法の総称
- 単純に分類ラベルを予測するのではなく、「似ているデータは近く、異なるデータは遠く」に分布する特徴空間を学習する

#### 背景
- 検索、照合、クラスタリング、顔認証などでは距離の良し悪しが精度を左右する
- 通常の距離（ユークリッド距離など）では、元データの特徴を正しく反映できない場合が多い
- 距離学習ではニューラルネットや行列分解などを用いて「適切な距離関数」や「埋め込み空間」を学習
- 特徴
    - 分類器不要（距離と閾値だけで判定可能）
    - 新クラスに対しても学習済み距離空間で対応できる（Few-shot Learningに強い）
    - 学習時のデータペア／トリプレット選びが重要

### Siamese Network
- ペアの入力（似ている／似ていない）を使い、距離を縮めたり広げたりする
- 損失関数にコントラスト損失（Contrastive Loss）を使用

#### コントラスト損失(Contrastive Loss)
$$
L = y \cdot D^{2} + (1 - y) \cdot \max(0, m - D)^{2}
$$

- $y \in \{0, 1\}$：ペアのラベル（1は類似ペア、0は非類似ペア）
- $D = \| f(x_i) - f(x_j) \|_2$：2つの特徴ベクトル間のユークリッド距離
- $m > 0$：マージン（距離の閾値）

### Triplet Network
- アンカー(A)、ポジティブ(P)、ネガティブ(N) の3つをセットで学習
    - アンカー（A）：基準となる入力サンプル
    - ポジティブ（P）：アンカーと同じクラスのサンプル
    - ネガティブ（N）：アンカーと異なるクラスのサンプル


#### トリプレット損失(Triplet Loss)
$$
L = \max\big(0, d(f(A), f(P)) - d(f(A), f(N)) + \alpha \big)
$$

- f(A),f(P),f(N) ：アンカー、ポジティブ、ネガティブの特徴ベクトル
- d(⋅,⋅) ：距離関数（通常ユークリッド距離）
- α>0 ：マージン