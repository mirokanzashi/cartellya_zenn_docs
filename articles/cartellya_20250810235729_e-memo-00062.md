---
title: "判断根拠の可視化"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- モデルをが出した予測の判断根拠を人間が理解できる形で提示する手法を勉強する

## キーワード
XAI, CAM, Global Average Pooling, Grad-CAM

## 学習内容

### XAI(Explainable AI, 説明可能な人工知能)
- AIモデルが出した予測や判断の理由・根拠を人間が理解できる形で提示する技術や研究分野のこと
- 高い説明責任が必要な分野では、AIがなぜその結論に至ったかを説明できなければ、信頼や採用が難しくなる
    - 医療：AIが「この腫瘍は悪性」と診断 → 医師は「どの特徴からそう判断したのか」を知る必要がある
    - 金融：AIが「この顧客には融資不可」と判断 → 顧客や監督機関に理由を説明する必要がある

#### 主なアプローチ
- モデル透明性（モデル自体をわかりやすくする）
    - ホワイトボックスモデルの使用（決定木、線形回帰、ルールベースなど）
    - モデル構造自体が人間に理解しやすい
-  事後説明（ブラックボックスでも理由を推定して説明）
    - LIME（Local Interpretable Model-agnostic Explanations）：局所的に近似モデルを作り、予測の要因を説明
    - SHAP（SHapley Additive exPlanations）：特徴量の寄与度をゲーム理論的に算出
    - Grad-CAM（画像系）：CNNのどの領域が分類に影響したかを可視化

#### XAIの意義
- 透明性：ブラックボックス解消
- 信頼性：ユーザーがAIの判断を安心して受け入れられる
- 責任追跡：誤判断が起きたときに原因究明が可能
- 法規制対応：EU AI規制やGDPRの「説明を受ける権利」など

### CAM(Class Activation Mapping)
- CNNが画像分類の際に、どの領域を重視してそのクラスだと判断したのかを可視化する手法
- XAIの手法の1つで、画像認識のモデルで、特定のクラスに寄与したとされる入力領域をハイライトさせる手法
- 特定の条件を満たすネットワーク構造（最後の畳み込み層の後にGlobal Average Pooling (GAP) を置き、その出力を全結合層で分類）で使える
    - 最後にGAPを持つ特定の構造でしか使えない
- 使用のイメージ
    - 猫の画像を分類 → CAMは「耳・ひげ・目」の部分が赤くなる
    - 自動運転で「歩行者」と認識 → CAMで人の輪郭が赤く強調される

### Global Average Pooling(GAP)
- 特徴マップ全体の平均値を1つの数値に変換するプーリング手法で、主にCNNの出力層直前で使われる
- 各チャネルごとに、空間方向の情報を全部平均してしまう処理


#### 特徴
- パラメータ不要：全結合層のように重みは学習しない
- 過学習を抑制：モデルが小さくなるため、学習データへの依存が減る
- 空間的な位置情報は消える：平均化するので、細かい位置はわからなくなる

#### 利用例

```
[畳み込み層] → [最後のConv層の特徴マップ] → [Global Average Pooling] → [全結合(Softmax)]
```

- 各チャネルの「全体的な活性度」をクラス分類に使う
- CAM（Class Activation Mapping）では、このGAPの重みを利用して重要領域を可視化


### Grad-CAM(Gradient-weighted Class Activation Mapping)
- CAMの計算で使っている各特徴マップの重み付けの部分とGAPの部分を、逆伝播時の勾配で代用する事で、GAPを使用しないモデルにも適用出来るようになる

#### 特徴
- モデル非依存性：最後にGAPがなくても適用可能
- 柔軟性：画像分類だけでなく、物体検出・画像キャプションなどにも使える
- 直感的：ヒートマップとして「注目領域」がわかる

#### 計算手順
- クラスcに対して、Grad-CAMを計算する

1. 対象のクラススコア$y^c$を取得（Softmax前の出力）
2. 最後の畳み込み層の特徴マップ$A^k$を取得
    - kはチャネル番号
3. チャネルごとの重み$\alpha_k^c$を計算
勾配を空間方向に平均化：

$$
\alpha_k^c = \frac{1}{Z} \sum_{i} \sum_{j} \frac{\partial y^c}{\partial A^k_{ij}}
$$

- Zは特徴マップの画素数(H×W)
- この重みは「チャネルkがクラスcにどれだけ貢献しているか」を表す

4. クラス活性化マップの生成

$$
L_{\text{Grad-CAM}}^c = \mathrm{ReLU} \left( \sum_{k} \alpha_k^c \cdot A^k \right)

$$

- ReLUは、負の寄与を除外して正の寄与のみを残す

5. ヒートマップ化 & 画像に重畳
出力を元画像サイズに補間して重ねる

文字で簡単に説明すると

1. 画像を入力し、順伝播の畳み込み層と分類結果を得る
2. 分類結果を元に誤差逆伝搬し、畳み込み層の勾配を計算
3. それぞれの畳み込み層の勾配のGAPを計算
4. GAPを重みとした畳み込み層の重み付き和を取り、元の画像サイズにリサイズする

#### 比較
| 項目    | CAM          | Grad-CAM      |
| ----- | ------------ | ------------- |
| 適用範囲  | GAP構造のCNNのみ  | ほぼすべてのCNN     |
| 必要情報  | 特徴マップ＋分類層の重み | 特徴マップ＋勾配      |
| 計算コスト | 低い           | やや高い（勾配計算が必要） |
