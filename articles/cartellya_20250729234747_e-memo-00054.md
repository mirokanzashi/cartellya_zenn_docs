---
title: "セマンティックセグメンテーション"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- セマンティックセグメンテーションと主要なモデルを勉強する

## キーワード
セマンティックセグメンテーション, FCN, アップサンプリング, 転置畳み込み, 
スキップコネクション, SegNet, U-Net, パノプティックセグメンテーション

## 学習内容

### セマンティックセグメンテーション(Semantic Segmentation)
- 画像内のすべてのピクセルに対して「どのクラスに属しているか」を予測するタスク
- 使用される主なモデル：FCN、U-Netなど

#### 特徴
| 項目      | 内容                                |
| ------- | --------------------------------- |
| 目的   | ピクセルごとに「意味的なカテゴリ」（人、道路、空など）を割り当てる |
| 単位   | ピクセル                              |
| 入力   | 画像（例：512×512ピクセル）                              |
| 出力   | 入力画像と同じサイズの「クラスマップ」               |
| ラベル | 「カテゴリ（例：車、人、犬）」だけで、個体の区別はしない   |

#### 他のタスクの違い
| タスク                        | 説明                       | 出力例                |
| -------------------------- | ------------------------ | ------------------ |
| 画像分類                   | 画像全体に1つのラベルを付ける          | 「犬」                |
| 物体検出 | 複数の物体をバウンディングボックスで検出 | 「人（x,y,w,h）」       |
| セマンティックセグメンテーション       | 画像中のすべてのピクセルをカテゴリ分け      | 「このピクセルは犬」         |
| インスタンスセグメンテーション        | セマンティック＋「個体識別」も行う        | 「犬1のピクセル」「犬2のピクセル」 |

### FCN(Fully Convolutional Network)
- 畳み込み層とプーリング層のみで構成される(全結合層を持たない)アーキテクチャ
    - 従来のCNN（例:VGGやAlexNetなど）は、画像をクラス分類するモデルであり、最後に全結合層を使ってクラスラベルを出力する
    - FCNでは、この全結合層を畳み込み層に置き換えることで、画像全体のセグメンテーションマップ（各画素のクラス）を出力するように改良された
- 問題点：フィルターサイズにより、大きさがマッチしない(特に大きい)対象物についてはうまく認識・分類ができない

#### 特徴
| 特徴                 | 説明                                    |
| ----------------------------- | ------------------------------- |
| end-to-endのセグメンテーション      | 入力画像から、同じ解像度（または近い解像度）の出力画像を得る。各ピクセルがクラスに分類される。                             |
| 全結合層を使わない                 | 完全に畳み込み層で構成されるため、任意サイズの画像でも入力可能　|
| ダウンサンプリングとアップサンプリングの組み合わせ | CNNのプーリングによって解像度が下がるが、最終的に転置畳み込みや補間を用いて元の解像度に戻す |


#### 構造
> 入力画像 → 特徴抽出（バックボーン） → スコアマップ → アップサンプリング → 出力ラベルマップ

**特徴抽出（バックボーン）**
通常のCNN（例: VGG16など）をバックボーンとして使用する。これによって、画像から抽象的な特徴マップを得る
VGGでは、畳み込み＋プーリングの繰り返しで、解像度がどんどん下がっていく

**スコアマップの生成**
通常の画像分類では全結合層を通して最終的な「クラスラベル」を出力するが、FCNではこれを畳み込み層に置き換え
る
このようにして、最後に得られるのは「小さいサイズの特徴マップ（スコアマップ）」である
各位置には各クラスのスコアが格納されている

**アップサンプリング（転置畳み込み）**
得られたスコアマップは、元画像よりもかなり小さい（例えば1/32サイズ）
そのため、Deconvolution（転置畳み込み）を使って、元の解像度に戻す（アップサンプリング）必要がある
スキップコネクションを使う場合もある

### アップサンプリング
- 画像や特徴マップの解像度を引き伸ばす操作全般を指す

| 種類                          | 内容              | 特徴         |
| --------------------------- | --------------- | ---------- |
| 最近傍補間（Nearest Neighbor） | 一番近いピクセルの値をコピー  | 速いが粗い      |
| バイリニア補間（Bilinear）       | 周囲のピクセルを使って線形補間 | なめらかだがぼやける |
| 転置畳み込み                  | 畳み込みの逆操作、学習可能   | 精度高いが複雑    |

:::message
アップサンプリングは広い意味の総称であり、「Unpooling」や「UpSampling」はその中の具体的な手法であること
目的（解像度の復元）は共通している
:::


### 転置畳み込み(Transposed Convolution, Deconvolution)
- 畳み込みの逆操作に相当する演算
- 小さい特徴マップを大きくする（= 解像度を上げる）操作である
- アップサンプリングの方法の一つ
- 目的：ダウンサンプリング（プーリングなど）で下げた解像度を復元

#### 一般的な畳み込みとの比較
| 操作      | 入力 → 出力   | 目的       |
| ------- | --------- | -------- |
| 通常の畳み込み | 大きい → 小さい | 特徴抽出・圧縮  |
| 転置畳み込み  | 小さい → 大きい | 解像度を元に戻す |


### スキップコネクション(Skip Connection)
- 深い層の出力だけでなく、浅い層の出力も使って予測に活用する構造である

#### 目的
- 深い層は意味的な情報（何が写っているか）を持つが、空間的な情報（どこにあるか）は失われがち
- 浅い層は空間的な情報（位置、境界）を多く持っている
- 両者を融合することで、精度の高いセグメンテーションが可能になる


### SegNet
- セマンティックセグメンテーションのために設計されたエンコーダ・デコーダ型の深層畳み込みニューラルネットワークである
- 目的：
    - ピクセルごとに意味ラベルを予測
    - 解像度の高い予測マップを生成するために、アップサンプリングの方法に工夫がある
- 特徴：プーリング時に「どの位置が最大だったか（インデックス）」を記録して、decoder側で「そのインデックスだけを元に戻す」。これにより、より正確な空間位置情報を復元できる
- 問題点：encoderとdecoderが直列に接続されているため、特徴が伝搬する過程で細かな空間的情報（位置・境界・形状など）が失われてしまい、元の画像に対して最終的なセグメンテーションマップが粗くなりやすい
    - 細かい輪郭、物体の境界、微細な形状がうまく再現されない

#### 構造
**encoder**
入力画像から特徴マップを抽出する
各プーリング操作で「最大値のインデックス」も保存

**decoder**
プーリングで失われた解像度を復元
保存しておいたインデックスを使って、元の位置にUnpooling
転置畳み込み（学習可能なアップサンプリング）は使わず、固定的に元の空間に復元


### U-Net
- encoder-decoder構造 ＋ スキップ接続で構成されるアーキテクチャ
    - encoder: 畳み込み層とプーリング層
    - decoder: アップサンプリング
- モデルの構造が「U字型」になっている
- 医療画像分野で非常に高い精度を発揮する


#### 構造
| レベル | 解像度     | 処理             | スキップ接続の流れ               |
| --- | ------- | -------------- | ----------------------- |
| 1層目 | 256×256 | エンコーダの浅い層で畳み込み | デコーダの最後のアップサンプリング後の層に連結 |
| 2層目 | 128×128 | 畳み込み＋プーリング     | デコーダの次のアップサンプリング後の層に連結  |
| 3層目 | 64×64   | 同上             | 同上                      |
| 4層目 | 32×32   | ボトルネック         | デコーダのボトム（最深層）           |

- エンコーダは畳み込みとプーリングで徐々に解像度を下げていき、抽象的な特徴を抽出する
- デコーダは転置畳み込みや補間で解像度を元に戻すが、単純にアップサンプリングするだけだと、細かい空間情報が不足し、セグメンテーション結果が粗くなる
- エンコーダの各段階で得られた特徴マップ（高解像度のもの）を保存し、デコーダの対応するアップサンプリング直前の層にコピー（通常は「チャネル方向に連結(concatenate)」）して渡す
- こうすることで、デコーダは抽象的特徴と空間的特徴を一緒に使いながら、細かいピクセル単位の情報を復元できる

:::message
言い換えると、デコーダは、アップサンプリングで解像度をあげる度に、対応するエンコーダの同じ解像度の特徴マップを結合して処理を続ける。
:::

**チャネル方向に連結(concatenate)する理由**
- 連結することで、エンコーダからの特徴とデコーダの特徴が区別されたまま一緒に使える
- これにより、ネットワークはどちらの情報が必要かを学習しやすくなる


```
エンコーダ：                            デコーダ：
入力画像 → conv → maxpool(256×256)   ──┐
                     │                │
         conv → maxpool(128×128) ─────┼──── concat → upconv(128×128)
                     │                │
         conv → maxpool(64×64)   ─────┼──── concat → upconv(64×64)
                     │                │
         conv (ボトルネック32×32)      └──── concat → upconv(32×32)

```

![](/images/e-memo-00054_01.png)
*出典：
Ronneberger, O., Fischer, P., & Brox, T. (2015, October). U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention (pp. 234-241). Cham: Springer international publishing.,https://arxiv.org/abs/1505.04597*


### セグメンテーションモデルの比較
| モデル        | アップサンプリング方法                      | 特徴                        |
| ---------- | -------------------------------- | ------------------------- |
| FCN    | 転置畳み込み（学習あり）                     | スキップ接続あり、柔軟だがアーティファクト出やすい |
| U-Net  | 補間 or 転置畳み込み + スキップ接続            | 医療分野で定番、高精度               |
| SegNet | Unpooling（最大プーリングのインデックスを使用） | 軽量で構造がシンプル、空間情報を保持しやすい    |


### パノプティックセグメンテーション(Panoptic Segmentation)
- パノプティックとは、「全体を見渡す」という意味で、セマンティックセグメンテーションとインスタンスセグメンテーションの統一的な手法

| 手法                   | 説明                                | 例                  |
| -------------------- | --------------------------------- | ------------------ |
| セマンティックセグメンテーション | 各ピクセルに「クラスラベル」をつける（例：すべての木＝同じラベル） | 「空」「道」「車」など        |
| インスタンスセグメンテーション  | 各物体（インスタンス）を個別に分離しながらラベルづけ    | 「車①」「車②」「人①」「人②」など |
| パノプティックセグメンテーション  | セマンティックセグメンテーション +  インスタンスセグメンテーション   | クラスラベル（例：人、車、空、道）とインスタンスID（同じクラスでも別の物体なら別ID） |

![](/images/e-memo-00054_02.png)
*出典：
Kirillov, A., He, K., Girshick, R., Rother, C., & Dollár, P. (2019). Panoptic segmentation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9404-9413).,https://arxiv.org/pdf/1801.00868*
