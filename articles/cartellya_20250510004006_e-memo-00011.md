---
title: "機械学習のデータ検証"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- 機械学習の検証方法を知ります

## キーワード
ホールドアウト法, k-分割交差検証法

## 学習内容

### ホールドアウト法(Hold-Out Method)
- データセットを訓練用とテスト用に分割して評価する方法です
- 必要な時に、訓練用、検証用とテスト用に分割します


#### 特徴
| 項目    | 内容                                   |
| ----- | ------------------------------------ |
| シンプルさ | 1回だけ分割するだけなので、非常に簡単で速い               |
| スピード  | 訓練も評価も1回で済むため、計算が非常に軽い           |
| デメリット | 分割の仕方によって結果が大きく変わることがある（偏りが出やすい） |

- データ数が少ない場合には向いていません

#### 分割の仕方
- 訓練用80%、テスト用20%：一般的なパターン
- 訓練用70%、テスト用30%：訓練用データが多い場合
- 訓練用70%、検証用30%、テスト用30%：ディープラーニングで検証データを使う場合

![](/images/e-memo-00011_01.png)
*出典：
Anber Arif, How Cross-Validation Works In Machine Learning(2020), https://dataaspirant.com/cross-validation/*

### k-分割交差検証法（k-fold cross validation）
- モデルの汎化性能を安定して評価する代表的な交差検証手法です
- 収集したデータをk個の等しいサイズの部分(fold)で分割し、各foldを一度ずつ検証用として使い、残りのk-1個を訓練に使って繰り返し学習・評価する方法です

#### メリット
| 項目         | 内容                     |
| ---------- | ---------------------- |
| データを無駄にしない | 全データが一度は訓練または評価に使われる   |
| 評価が安定する    | テストデータの偏りを平均化できる       |
| 過学習の検出に強い  | 何度も異なる検証データで試すため信頼性が高い |

#### デメリット
| 項目             | 内容                         |
| -------------- | -------------------------- |
| 計算コストが高い       | k回モデルを学習する必要がある            |
| データが非常に少ないと不安定 | 各foldが小さくなり、性能評価がばらつくことがある |

#### 処理の流れ（例：k=5）
1. データを 5個のfoldに等分する(fold1~fold5)
2. 各回で1つを検証用に使い、他の4つで訓練する
3. 合計5回、モデルを学習&評価する
4. 5回分の評価指標の平均値を最終性能とする

![](/images/e-memo-00011_02.png)
*出典：
Anber Arif, How Cross-Validation Works In Machine Learning(2020), https://dataaspirant.com/cross-validation/*