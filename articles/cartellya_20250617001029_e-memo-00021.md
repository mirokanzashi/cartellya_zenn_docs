---
title: "出力層の活性化関数の微分"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- 出力層の活性化関数の微分結果を覚える
- 逆伝播で各活性化関数の微分の特徴を勉強する

#### モデル訓練のステップ
1. アーキテクチャの設計
2. 入力層設計
3. 中間層設計
4. 出力層設計
5. 誤差計算
6. **モデルに誤差を反映する**
7. 重みの更新の設定をする
8. 最適なモデルを手に入れる

## キーワード
なし

## 学習内容

### シグモイド関数の微分
https://zenn.dev/cartellya/articles/cartellya_20250617001019_e-memo-00020


### ソフトマックス関数の微分

$$
y_i = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}
$$

$$
\frac{\partial y_i}{\partial x_j} = 
\begin{cases}
y_i (1 - y_i) & \text{if } i = j \\
- y_i y_j & \text{if } i \ne j
\end{cases}
$$

:::message
暗記しよう
:::