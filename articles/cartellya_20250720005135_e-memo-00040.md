---
title: "正規化"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- ニューラルネットワークの正規化手法を勉強する

## キーワード
Batch Normalization, Layer Normalization,
Instance Normalization, Group Normalization

## 学習内容

### バッチ正規化（Batch Normalization）
- ニューロンの出力（活性化）に対して、バッチごとに平均と標準偏差を計算し正規化を行う手法
- ニューラルネットワークでは、層が深くなるにつれて入力の分布が変わってしまい、勾配消失や学習の不安定が起きやすくなる。これを抑えるために、各層の入力を平均0・分散1になるように調整することがバッチ正規化である
- バッチ正規化はバッチ全体で平均と分散を計算するため、入力データごとにシーケンス長が異なる自然言語処理（NLP）のようなタスクには適していない


### レイヤー正規化（Layer Normalization）
- 目的はバッチ正規化と同じく、要素を正規化する
    - ただ、今回の対象はバッチではなく、一つのサンプルである
- バッチ内のデータ構造（形状）が固定されていることが前提となる。しかし、この前提は「可変長のシーケンスを扱う言語モデルのようなタスク」では成り立ったない。レイヤー正規化はこの課題を解決する
- RNN・Transformerのような時系列・構造入力に最適

:::message
**バッチとサンプル**
バッチ：学習の効率化のために、複数の入力サンプルをまとめたもの。「バッチサイズ」は、1回にまとめて処理するサンプルの数
サンプル：1つのデータ例（例：1枚の画像、1文のテキスト、1行の特徴ベクトルなど）。ニューラルネットワークに与える最小単位のデータ
:::

### インスタンス正規化（Instance Normalization）
- 1つの入力サンプルの中で、チャネルごとに正規化を行う手法
- 画像スタイル変換や画像生成(GAN)などのタスクでよく使われる

**画像スタイル変換の例**
![](/images/e-memo-00040_01.png)
*出典：
Ulyanov, D., Vedaldi, A., & Lempitsky, V. (2016). Instance normalization: The missing ingredient for fast stylization. arXiv preprint arXiv:1607.08022.*



### グループ正規化（Group Normalization）
- チャネルをいくつかのグループに分けて、その中で正規化する手法
#### 経緯
- バッチ正規化はバッチ数が小さいと平均・分散の推定が不安定になり、学習が非効率になってしまうというメリットがある
- 改善として、バッチ中の複数のサンプルを使うのではなく、1つのサンプルだけを使って平均・分散を計算するという方法が考えられた
    - レイヤー正規化はRNNなどの時系列モデルで提案された
    - インスタンス正規化は画像のスタイル変換のモデルで提案された
#### グループ正規化とは
- グループ正規化はレイヤー正規化とインスタンス正規化の間のような仕組みである
- インスタンス正規化と比べると、グループ正規化がグループ単位で正規化するので表現力が高く、汎化性もよい
- バッチサイズに依存しないので、小バッチや1サンプルでも安定

| 性質            | バッチ正規化  | グループ正規化 | インスタンス正規化  |
| ------------- | ---------- | ------------- | ------------- |
| バッチ方向を使うか     | 使う       | 使わない        | 使わない        |
| チャネルごとに独立か    | 独立（各Cごと） | グループ単位（複数C） | 完全に独立（各Cごと） |
| 正規化範囲         | N方向        | C/G方向         | C方向           |
| 空間方向(H×W)を使うか | 使う       | 使う          | 使う          |


### まとめ
![](/images/e-memo-00040_02.png)
*出典：
Wu, Y., & He, K. (2018). Group normalization. In Proceedings of the European conference on computer vision (ECCV) (pp. 3-19).*

- N = バッチサイズ  
- C = チャネル数（特徴マップ）  
- H, W = 高さ・幅（空間）

| 手法               | 正規化する要素        | 特徴             |
| ---------------- | ----------------------------- | --------------------------- |
| バッチ正規化    | 各チャネルに対し、バッチ全体と空間（N×H×W）  | バッチ依存、チャネルごとに空間も含めて正規化      |
| レイヤー正規化    | 各サンプルの全チャネル・空間（C×H×W）    | サンプル単位、全チャネルと空間をまとめて正規化  |
| インスタンス正規化 | 各サンプル・チャネルごとに空間（H×W）  | サンプルとチャネルごとに空間のみを正規化   |
| グループ正規化    | 各サンプルのチャネルをGグループに分け、(C/G×H×W) | サンプル単位、チャネルをグループ分けして空間含め正規化 |
