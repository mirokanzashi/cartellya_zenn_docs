---
title: "計算グラフ"
emoji: "✅"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["学習記録","ニューラルネットワーク"]
published: true
---

## はじめに
:::message alert
記事内容は筆者の勉強まとめ内容です。内容の正確さや漏れについては保証できません。
ご覧いただく際は、ご自身で判断のうえ参考にしてください。
:::


## 概要
- シラバス：E資格2024#2
- 計算グラフで順伝播と逆伝播の計算を勉強する


#### モデル訓練のステップ
1. アーキテクチャの設計
2. 入力層設計
3. 中間層設計
4. 出力層設計
5. 誤差計算
6. モデルに誤差を反映する
7. **重みの更新の設定をする**
8. 最適なモデルを手に入れる

## キーワード


## 学習内容

### 計算グラフ
- 計算を可視化する方法の1つで、計算を視覚的に理解が出来るようにしたもの

#### 加算
z = x + y
L = f(z)
L：誤差関数

**順伝播**


![](/images/e-memo-00024_01.png)

**逆伝播**
![](/images/e-memo-00024_04.png)

#### 乗算
z = xy
L = f(z)
L：誤差関数

**順伝播**

![](/images/e-memo-00024_02.png)

**逆伝播**
![](/images/e-memo-00024_05.png)

#### 活性化関数
h = wx
u = h + b
y = f(u)
L = g(y)
L：誤差関数
f：活性化関数
b：バイアス



**順伝播**
![](/images/e-memo-00024_03.png)

**逆伝播**
![](/images/e-memo-00024_06.png)

**行列の逆伝播の場合**

$$
\frac{\partial L}{\partial X} = \frac{\partial L}{\partial Y} \cdot W^T

$$
$$
\frac{\partial L}{\partial W} = X^T  \cdot \frac{\partial L}{\partial Y}

$$